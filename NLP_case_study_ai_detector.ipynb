{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06da537bf5604ce1940ae42282921d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f412d9d6faf4c9394204a9b2999ed94",
              "IPY_MODEL_3216be36e02646a5b2bc3507e8d0c631",
              "IPY_MODEL_5aac6814f055426bab1037ddab7db4c9"
            ],
            "layout": "IPY_MODEL_24d20250e12c4319a31dc9dc392abc96"
          }
        },
        "2f412d9d6faf4c9394204a9b2999ed94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5a366a1c4554eb29e9ccb9088ebb842",
            "placeholder": "​",
            "style": "IPY_MODEL_7d28925720a84963944644f8420b799c",
            "value": "Loading checkpoint shards:  50%"
          }
        },
        "3216be36e02646a5b2bc3507e8d0c631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a6040a622b846159e2caa2e5fbff7d8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_429a6911ef3647d4acdfc94098106f9a",
            "value": 1
          }
        },
        "5aac6814f055426bab1037ddab7db4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e9535f999c6487a95e22becc3062511",
            "placeholder": "​",
            "style": "IPY_MODEL_bc3602574c8448e0a1f0c647bc467c92",
            "value": " 1/2 [00:24&lt;00:24, 24.38s/it]"
          }
        },
        "24d20250e12c4319a31dc9dc392abc96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a366a1c4554eb29e9ccb9088ebb842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d28925720a84963944644f8420b799c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a6040a622b846159e2caa2e5fbff7d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "429a6911ef3647d4acdfc94098106f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e9535f999c6487a95e22becc3062511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc3602574c8448e0a1f0c647bc467c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"harsh4248/human_vs_llm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sQ104_jxd_V",
        "outputId": "3b8918f0-b45a-40c6-b81a-ef906052700f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_labels(dataset_split):\n",
        "    return [example['label'] for example in dataset_split]\n",
        "\n",
        "train_labels = extract_labels(dataset['train'])\n",
        "all_labels = train_labels"
      ],
      "metadata": {
        "id": "spFlkYxNxxu9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(all_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGiANEimzpI0",
        "outputId": "342bafc6-3f47-4fc7-fc60-cdafdbc71214"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Bloom-7B',\n",
              " 'Claude-Instant-v1',\n",
              " 'Claude-v1',\n",
              " 'Cohere-Command',\n",
              " 'Dolphin-2.5-Mixtral-8x7B',\n",
              " 'Dolphin-Mixtral-8x7B',\n",
              " 'Falcon-180B',\n",
              " 'Flan-T5-Base',\n",
              " 'Flan-T5-Large',\n",
              " 'Flan-T5-Small',\n",
              " 'Flan-T5-XL',\n",
              " 'Flan-T5-XXL',\n",
              " 'GLM-130B',\n",
              " 'GPT-3.5',\n",
              " 'GPT-4',\n",
              " 'GPT-J',\n",
              " 'GPT-NeoX',\n",
              " 'Gemini-Pro',\n",
              " 'Goliath-120B',\n",
              " 'Human',\n",
              " 'LLaMA-13B',\n",
              " 'LLaMA-2-70B',\n",
              " 'LLaMA-2-7B',\n",
              " 'LLaMA-30B',\n",
              " 'LLaMA-65B',\n",
              " 'LLaMA-7B',\n",
              " 'LZLV-70B',\n",
              " 'Mistral-7B',\n",
              " 'Mistral-7B-OpenOrca',\n",
              " 'Mixtral-8x7B',\n",
              " 'MythoMax-L2-13B',\n",
              " 'Neural-Chat-7B',\n",
              " 'Noromaid-20B',\n",
              " 'Nous-Capybara-34B',\n",
              " 'Nous-Capybara-7B',\n",
              " 'Nous-Hermes-LLaMA-2-13B',\n",
              " 'Nous-Hermes-LLaMA-2-70B',\n",
              " 'OPT-1.3B',\n",
              " 'OPT-125M',\n",
              " 'OPT-13B',\n",
              " 'OPT-2.7B',\n",
              " 'OPT-30B',\n",
              " 'OPT-350M',\n",
              " 'OPT-6.7B',\n",
              " 'OpenChat-3.5',\n",
              " 'OpenHermes-2-Mistral-7B',\n",
              " 'OpenHermes-2.5-Mistral-7B',\n",
              " 'PaLM-2',\n",
              " 'Psyfighter-13B',\n",
              " 'Psyfighter-2-13B',\n",
              " 'RWKV-5-World-3B',\n",
              " 'StripedHyena-Nous-7B',\n",
              " 'T0-11B',\n",
              " 'T0-3B',\n",
              " 'Text-Ada-001',\n",
              " 'Text-Babbage-001',\n",
              " 'Text-Curie-001',\n",
              " 'Text-Davinci-001',\n",
              " 'Text-Davinci-002',\n",
              " 'Text-Davinci-003',\n",
              " 'Toppy-M-7B',\n",
              " 'Unknown',\n",
              " 'YI-34B'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "changing labels to 0 if written by human and changing to 1 if written by ai"
      ],
      "metadata": {
        "id": "EhAygARc1Uqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_labels(example):\n",
        "    example['label'] = 0 if example['label'] == 'Human' else 1\n",
        "    return example\n",
        "\n",
        "# Apply the label modification function to the dataset\n",
        "dataset = dataset.map(modify_labels)"
      ],
      "metadata": {
        "id": "IMjgVUul04QU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "train_testvalid = dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
        "train_valid_dataset = DatasetDict({\n",
        "    'train': train_testvalid['train'],\n",
        "    'test': train_testvalid['test']\n",
        "})"
      ],
      "metadata": {
        "id": "xqJMqpITspS5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_valid_dataset['test'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnuKJ9dpuwXi",
        "outputId": "093dfaa4-4952-491d-c0b9-3f91e26746f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0,\n",
              " 'title': \"First off, let me make something clear: I'm not an anti-vaccer, and I dislike anti-vaccers. However, children do not have control over whether or not they're vaccinated; parents do. If a child is kept out of school during an outbreak, it is absolutely not their fault, yet one would end up being punished for it: first, academic performance will likely suffer. Second, one may be seen as an outcast whose parents are kind of nutty, and that may influence one's social life. Additionally, it is unjust that the parents, whose taxes pay for public schools (and who may not be able to afford other schools), will not be given the option to have their child go a public school. I believe that this is different from, for example, someone who pays taxes, but whose children go to a private school, because in that case, the parents still have the option of sending their children to a public school. However, I agree that sending unvaccinated children to school will increase the risk of other children, vaccinated or not, getting sick. So, what I propose is that the federal or state government maintain a list of diseases with known effective vaccines that all children are required by law to be vaccinated for within a certain frame of time, if it's possible. Parents might try to refuse on grounds of religion, but in the US (where I live), one is only free to practice their religion insofar as it doesn't break secular law. Also, since the parents' decision to refrain from vaccination harms their children (as well as other children, potentially), breaking this law wouldn't be a victimless crime, so the law wouldn't really be an infringement on personal freedom. Change my view, Reddit! Convince me that it's better to keep unvaccinated children from public school than to just force them to be vaccinated- or, convince me of an alternate solution to the outbreak-vaccination problem! Hello, users of CMV! This is a footnote from your moderators. We'd just like to remind you of a couple of things. Firstly, please remember to [read through our rules] . If you see a comment that has broken one, it is more effective to report it than downvote it. Speaking of which, [downvotes don't change views] ! If you are thinking about submitting a CMV yourself, please have a look through our [popular topics wiki] first. Any questions or concerns? Feel free to [message us] . Happy CMVing!\"}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_valid_dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnI6Jht80yGP",
        "outputId": "06fa4887-9b73-48b7-9993-1cabc2ca6c43"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 1,\n",
              " 'title': \"In the intricate tapestry of modern genetic science, the threads of ethical considerations are woven tightly with those of technological advancements. The evolution of forensic genetic genealogy is no exception, as it stands at the nexus of law enforcement, personal privacy, and historical rectification. This scientific technique, which uses DNA to trace lineage and ancestry, has far-reaching implications, especially in the realms of family reunification and reparations. The ethical landscape of these applications is a complex one, fraught with myriad questions about the rights of individuals, families, and communities.\\n\\nForensic genetic genealogy has gained public attention largely through its role in solving cold cases, where law enforcement agencies use public DNA databases to find relatives of suspects and ultimately identify the culprits. The success stories are compelling, bringing long-sought closure to victims' families. However, the use of genetic genealogy in such cases has raised serious privacy concerns. When someone submits their DNA to a database, they may unknowingly expose not only their genetic information but also that of their relatives, including those distant kin they may never have met. The ethical implications of this exposure must be carefully considered, especially when such information is used without the explicit consent of all individuals whose genetic data may be implicated.\\n\\nThe issue of consent is especially poignant in the context of family reunification. Families separated by adoption, immigration, or even the upheaval of war and conflict may turn to genetic genealogy as a beacon of hope in their search for lost relatives. Here, the use of genetic databases can be seen as a force for good, a tool to heal the wounds of separation. Yet, the delicate balance between the right to know one's biological heritage and the right to privacy of those who may not wish to be found or identified is an ethical tightrope. The very act of reuniting families could inadvertently trample on the privacy rights of others, sparking a need for policies that protect all parties involved.\\n\\nFurthermore, the use of genetic information extends beyond the personal sphere into the historical and societal, particularly when it comes to reparations. Marginalized groups who have suffered injustices such as slavery, genocide, and colonialism are increasingly looking to genetic genealogy to substantiate claims for reparations. The ability to trace ancestry can provide a tangible link to the past, one that reveals the undeniable connections between historical wrongs and present-day demographics. However, the ethical considerations here are magnified as the debate about reparations intersects with questions about who has the right to access and use genetic data. Can, or should, genetic information be used to determine eligibility for reparations? And what are the implications for privacy if genetic proof becomes a standard in such cases?\\n\\nThe potential to use genetic genealogy as a means to rectify historical injustices brings to light another ethical concern: the possibility of creating a genetic underclass. If genetic data becomes a commodity in the context of reparations, there is a risk that individuals could be discriminated against based on their inability to prove ancestry or the lack of genetic markers deemed necessary for compensation. Such discrimination could perpetuate the very injustices that reparations seek to address, creating a paradox at the heart of the quest for justice.\\n\\nMoreover, the commercialization of genetic data poses additional ethical questions. Private companies that offer genetic testing and maintain databases may prioritize profit over privacy, increasing the vulnerability of individuals' genetic information. Regulatory oversight is essential to ensure that these companies do not exploit the genetic data they collect, particularly when such information is used in sensitive contexts like family reunification and reparations.\\n\\nIn navigating these ethical complexities, several measures can be considered to strike a balance between the benefits of forensic genetic genealogy and the protection of individual rights. Informed consent should be the cornerstone of any genetic database, ensuring that individuals are fully aware of how their genetic information may be used and the potential implications for their relatives. Legislation can also play a critical role in safeguarding genetic privacy, with robust laws that regulate access to and use of genetic data by law enforcement, private companies, and other entities.\\n\\nThe establishment of ethical guidelines specific to the use of genetic genealogy in family reunification and reparations is also essential. These guidelines should address the needs and rights of all stakeholders, including those seeking family members, those who may be identified against their will, and communities advocating for reparations. Such guidelines must be informed by a broad range of perspectives, incorporating the insights of geneticists, ethicists, legal experts, and representatives from affected communities.\\n\\nIn conclusion, the ethical implications of genetic privacy in forensic genetic genealogy for family reunification and reparations are profound and multifaceted. They require a nuanced approach that values the potential benefits of this technology while vigilantly protecting individual and collective rights. As the science of genetic genealogy continues to evolve, so too must our ethical frameworks, ensuring that the quest for knowledge and justice does not come at the expense of the very humanity we seek to understand and repair. The path forward must be charted with careful consideration, empathy, and a commitment to upholding the dignity of all individuals whose lives are touched by the power of genetic discovery.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\", trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\", trust_remote_code=True)\n",
        "\n",
        "# Tokenize the data\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['title'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = train_valid_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set the format for PyTorch\n",
        "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Create the Trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=15,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['test'],\n",
        "\n",
        "\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation results: {eval_results}\")\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"./fine-tuned-model\")\n",
        "tokenizer.save_pretrained(\"./fine-tuned-model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "06da537bf5604ce1940ae42282921d43",
            "2f412d9d6faf4c9394204a9b2999ed94",
            "3216be36e02646a5b2bc3507e8d0c631",
            "5aac6814f055426bab1037ddab7db4c9",
            "24d20250e12c4319a31dc9dc392abc96",
            "c5a366a1c4554eb29e9ccb9088ebb842",
            "7d28925720a84963944644f8420b799c",
            "4a6040a622b846159e2caa2e5fbff7d8",
            "429a6911ef3647d4acdfc94098106f9a",
            "9e9535f999c6487a95e22becc3062511",
            "bc3602574c8448e0a1f0c647bc467c92"
          ]
        },
        "id": "Rt8cq4Ti1yQJ",
        "outputId": "a85eaaa6-90c1-4b89-9a7a-62234ef8b635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.5be6479b4bc06a081e8f4c6ece294241ccd32dec.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.5be6479b4bc06a081e8f4c6ece294241ccd32dec.modeling_phi3:Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06da537bf5604ce1940ae42282921d43"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}